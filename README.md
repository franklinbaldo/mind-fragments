# Google Drive and LLM Integration Test

This project demonstrates an end-to-end integration of fetching Google Drive activity, extracting text content from a selected file (prioritizing Google Documents), and processing that content with a Google Gemini Pro LLM to generate blog-worthy text with PII removed.

The system consists of three main Python scripts:
1.  `fetch_drive_activity.py`: Connects to Google Drive, fetches metadata of recent files, and can export Google Document content.
2.  `llm_interaction.py`: Interfaces with the Google Gemini Pro LLM to process text.
3.  `run_integration_test.py`: Orchestrates the integration test by using the other two modules.

## Prerequisites

Before running the integration test, ensure you have the following:

1.  **Python Environment:**
    *   Python 3.7+
    *   Install necessary libraries:
        ```bash
        pip install -r requirements.txt
        ```
        (The `requirements.txt` should include `google-api-python-client`, `google-auth-httplib2`, `google-auth-oauthlib`, and `google-generativeai`.)

2.  **Google Drive API Credentials (`credentials.json`):**
    *   Set up a Google Cloud Project and enable the Google Drive API.
    *   Create OAuth 2.0 credentials for a "Desktop app".
    *   Download the credentials JSON file and save it as `credentials.json` in the same directory as the scripts.
    *   The first time `fetch_drive_activity.py` (or `run_integration_test.py`) runs, it will open a browser window for you to authorize access. Upon successful authorization, a `token.json` file will be created to store your access tokens for future runs.

3.  **Google Generative AI API Key (`GEMINI_API_KEY`):**
    *   Obtain an API key from [Google AI Studio](https://makersuite.google.com/).
    *   Set this key as an environment variable named `GEMINI_API_KEY`.
        *   **Linux/macOS:** `export GEMINI_API_KEY="YOUR_API_KEY_HERE"` (add to `~/.bashrc` or `~/.zshrc` for permanence).
        *   **Windows (Command Prompt):** `setx GEMINI_API_KEY "YOUR_API_KEY_HERE"` (may require terminal restart).
        *   **Windows (PowerShell):** `$Env:GEMINI_API_KEY="YOUR_API_KEY_HERE"` (for current session; use system environment variable settings for permanence).

## How to Run the Integration Test

1.  Ensure all prerequisites above are met (`credentials.json` is present, `GEMINI_API_KEY` is set, libraries installed).
2.  Navigate to the directory containing the scripts (`fetch_drive_activity.py`, `llm_interaction.py`, `run_integration_test.py`).
3.  Execute the integration test script from your terminal:

    ```bash
    python run_integration_test.py
    ```

## What the Script Does

The `run_integration_test.py` script performs the following steps:

1.  **Checks Prerequisites:** Verifies the existence of `credentials.json` and the `GEMINI_API_KEY` environment variable.
2.  **Fetches Drive Activity:** Calls `fetch_drive_activity.main()` to:
    *   Authenticate with the Google Drive API (creating/updating `token.json`).
    *   Fetch metadata for the 20 most recently modified files in your Google Drive.
    *   Save this metadata to `google_drive_activity.json`.
3.  **Selects Data:** Reads `google_drive_activity.json` and selects the first file listed.
4.  **Extracts Text Content:**
    *   If the selected file is a Google Document (`application/vnd.google-apps.document`), it attempts to download its content as plain text using `fetch_drive_activity.get_google_doc_content_as_text()`.
    *   If it's another type of file or if content extraction fails, it uses the file's metadata (name, type, etc.) as the input text.
5.  **Processes with LLM:**
    *   Prints a sample of the text being sent to the LLM.
    *   Calls `llm_interaction.process_text_with_llm()` with the extracted text and your `GEMINI_API_KEY`.
    *   The LLM is prompted to identify blog-worthy information, rewrite it in an engaging tone, and remove all PII.
6.  **Displays and Saves Output:**
    *   Prints the processed text received from the LLM to the console.
    *   Saves the full LLM output to a file named `llm_processed_sample_output.txt`.

## Expected Output

*   **Console Output:**
    *   Status messages from the script execution (prerequisite checks, Drive activity fetching, LLM processing steps).
    *   A sample of the text sent to the LLM.
    *   The full processed text returned by the LLM.
*   **Files Created/Updated:**
    *   `token.json`: Stores your Google Drive API OAuth tokens.
    *   `google_drive_activity.json`: Contains metadata of your recent Google Drive files.
    *   `llm_processed_sample_output.txt`: Contains the output from the LLM after processing the selected file's content/metadata.

## **IMPORTANT: Review and Feedback**

After the script completes, please **open and carefully review `llm_processed_sample_output.txt`**.

Your feedback on the following aspects is crucial for the next steps of this project:
*   **Relevance:** Is the content generated by the LLM relevant to the input text?
*   **PII Removal:** Has all Personal Identifiable Information (PII) been successfully removed? Check carefully for any missed names, emails, locations, etc.
*   **Tone and Style:** Is the tone engaging and suitable for a blog post?
*   **Overall Quality:** What is your general impression of the output? Are there any specific areas for improvement?

This feedback will be used to refine the PII detection, prompt engineering, and content generation capabilities of the system.
