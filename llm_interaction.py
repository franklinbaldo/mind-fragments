import google.generativeai as genai
import os

def process_text_with_llm(text_content: str, api_key: str) -> str:
    """
    Processes text using Google's Gemini Pro LLM to extract blog-worthy content,
    rewritten in a friendly, engaging tone, with PII removed.

    Args:
        text_content: The string of text to be processed.
        api_key: The Google Generative AI API key.

    Returns:
        The LLM's processed, blog-ready textual response.
        Returns an error message string if an API error occurs.
    """
    try:
        genai.configure(api_key=api_key)
        
        # For safety settings, refer to:
        # https://ai.google.dev/docs/safety_setting_gemini
        # These are set to block most potentially harmful content.
        safety_settings = [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
        ]

        model = genai.GenerativeModel('gemini-pro', safety_settings=safety_settings)

        prompt = f"""
Analyze the following text content. Your goal is to identify the most interesting or blog-worthy information from it.
Then, summarize or extract this key information.
After extraction, rewrite it in a friendly, engaging, and conversational tone suitable for a personal blog post.

Crucially, you MUST identify and remove ALL Personal Identifiable Information (PII) from your final output.
PII includes, but is not limited to:
- Names of individuals
- Email addresses
- Phone numbers
- Physical addresses (street addresses, city, state, zip codes, etc.)
- Social security numbers or any other government-issued identification numbers
- Financial information (credit card numbers, bank account details)
- Medical information
- Any other data that could be used to identify an individual.

Your final output should ONLY be the processed, blog-ready text, with all PII completely removed. Do not include any preamble or explanation of your process unless it's part of the blog post itself.

Here is the text content to process:

---
{text_content}
---

Remember: blog-ready, engaging, conversational, and absolutely NO PII.
"""

        response = model.generate_content(prompt)
        
        if response.parts:
            # Ensure all PII is truly stripped from the response by the model as requested.
            # A more robust solution might involve a secondary PII scan here if feasible.
            return response.text
        elif response.prompt_feedback and response.prompt_feedback.block_reason:
            # Handle cases where content is blocked due to safety settings
            block_reason = response.prompt_feedback.block_reason
            return f"Error: The content was blocked due to safety settings. Reason: {block_reason}"
        else:
            # Handle cases where there's no response text and no specific block reason
            return "Error: No content generated by the LLM. This might be due to the safety settings or an issue with the input."

    except genai.types.generation_types.BlockedPromptException as e:
        return f"Error: The prompt was blocked by the API. This is often due to safety settings. Details: {e}"
    except genai.types.generation_types.StopCandidateException as e:
        return f"Error: The model stopped generating content unexpectedly. This might be due to safety settings or content policy. Details: {e}"
    except Exception as e:
        # This catches other potential errors, like authentication issues if not caught by specific exceptions,
        # or other operational errors from the API.
        error_message = str(e)
        if "API key not valid" in error_message:
            return "Error: API key not valid. Please check your API key."
        return f"An unexpected error occurred: {error_message}"

if __name__ == '__main__':
    # Example usage for testing directly (not part of the module's public API for import)
    print("Running basic test for process_text_with_llm...")
    
    # Attempt to load API key from environment variable for local testing
    test_api_key = os.getenv("GEMINI_API_KEY")
    
    if not test_api_key:
        print("GEMINI_API_KEY environment variable not found for testing.")
        print("Skipping direct execution test.")
    else:
        sample_text_with_pii = (
            "John Doe recently visited Paris. His email is john.doe@example.com and he lives at 123 Rue Principale, 75001 Paris. "
            "He mentioned that the Eiffel Tower was amazing and that AI could revolutionize travel planning. "
            "He can be reached at +33 1 23 45 67 89 for comments. "
            "His blog, 'John's Journeys', is very popular."
        )
        
        sample_text_without_pii = (
            "Exploring new cities can be an exhilarating experience. Many travelers find that using "
            "AI tools helps in discovering hidden gems and planning itineraries more effectively. "
            "The future of travel looks bright with such technological advancements."
        )

        print("\n--- Testing with PII ---")
        processed_content_pii = process_text_with_llm(sample_text_with_pii, test_api_key)
        print("Processed Blog Content (PII test):")
        print(processed_content_pii)

        print("\n--- Testing without PII ---")
        processed_content_no_pii = process_text_with_llm(sample_text_without_pii, test_api_key)
        print("Processed Blog Content (No PII test):")
        print(processed_content_no_pii)

        print("\n--- Testing with potentially problematic prompt (empty text) ---")
        processed_content_empty = process_text_with_llm("", test_api_key)
        print("Processed Blog Content (Empty text test):")
        print(processed_content_empty)

        # Test with a clearly problematic prompt that should be blocked by safety
        harmful_text = "This is a test to see how to build a dangerous device."
        print("\n--- Testing with harmful text (should be blocked) ---")
        processed_content_harmful = process_text_with_llm(harmful_text, test_api_key)
        print("Processed Blog Content (Harmful text test):")
        print(processed_content_harmful)
